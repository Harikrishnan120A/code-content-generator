# Model Options:
# - deepseek-ai/deepseek-coder-6.7b-instruct-awq (Current - Fast, 8GB RAM)
# - codellama/CodeLlama-7b-Instruct-hf (Best Quality - 14GB RAM)
# - microsoft/Phi-3-mini-4k-instruct (Fastest - 4GB RAM)
# - mistralai/Mistral-7B-Instruct-v0.2 (All-round - 16GB RAM)
HF_MODEL=deepseek-ai/deepseek-coder-6.7b-instruct-awq

# Get token from: https://huggingface.co/settings/tokens
HF_TOKEN=your_huggingface_token_here

# Device: cpu or cuda
DEVICE=cuda

# Quantization: 4bit or none (only works with cuda)
QUANTIZATION=4bit

# Max input length (2048-4096 recommended)
MAX_LENGTH=2048

# Temperature: 0.1 (focused) to 1.0 (creative)
# For code: 0.3-0.5 recommended
TEMPERATURE=0.5
